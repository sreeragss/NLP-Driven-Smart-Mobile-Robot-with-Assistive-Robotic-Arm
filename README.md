# ğŸ¤– NLP-Driven Smart Mobile Robot with Assistive Robotic Arm

![Python](https://img.shields.io/badge/Python-3.7-blue?logo=python)
![Arduino](https://img.shields.io/badge/Arduino-UNO-green?logo=arduino)
![Raspberry Pi](https://img.shields.io/badge/Raspberry%20Pi-3B+-red?logo=raspberrypi)
![OpenCV](https://img.shields.io/badge/OpenCV-Computer%20Vision-orange?logo=opencv)
![License](https://img.shields.io/badge/License-MIT-lightgrey)

---

## ğŸ“Œ Project Overview  
This is my **M.Tech Mini Project (2025)** at *College of Engineering Trivandrum*.  
It presents a **smart mobile robotic assistant** that:  

- ğŸ¤ Understands **voice commands** using **NLP & Google Speech Recognition**  
- ğŸš— Navigates supermarket-style aisles with **ultrasonic obstacle detection**  
- ğŸ¯ Detects products via **computer vision (OpenCV + ArUco markers)**  
- ğŸ¦¾ Retrieves items using a **5-DOF robotic arm** with inverse kinematics  
- ğŸ‘µ Designed as an **assistive robot for elderly & physically challenged individuals**  

---

## âœ¨ Key Features  
âœ”ï¸ Voice-controlled shopping assistant  
âœ”ï¸ NLP for natural interaction  
âœ”ï¸ ArUco markerâ€“based product recognition  
âœ”ï¸ 5-DOF robotic arm with gripper  
âœ”ï¸ Autonomous navigation with obstacle avoidance  
âœ”ï¸ Raspberry Pi + Arduino integration  

---

## ğŸ› ï¸ Hardware Setup  
| Component            | Specification / Role |
|----------------------|----------------------|
| **Mobile Base**      | 4-wheel DC motor platform (L298N motor driver) |
| **Controller**       | Raspberry Pi 3B+ (NLP, vision, navigation) |
| **Robotic Arm**      | 5-DOF manipulator (3 Ã— MG996R + 3 Ã— SG90 servos) |
| **Microcontroller**  | Arduino UNO (servo control) |
| **Sensors**          | Ultrasonic sensors (front & rear) |
| **Camera**           | USB webcam (ArUco detection & pose estimation) |
| **Power**            | 5V, 5A regulated power supply + battery pack |

---

## ğŸ’» Software Stack  
- **Python 3.7** (control logic, NLP, vision, navigation)  
- **C++ (Arduino IDE)** (servo actuation)  
- **Libraries:**  
  - OpenCV (ArUco marker detection, pose estimation)  
  - NumPy  
  - Google Speech Recognition API  
  - PySerial (Raspberry Pi â†” Arduino comms)  

---

## ğŸš€ System Workflow  
1. ğŸ¤ **User Command** â†’ â€œPick the red box from Shelf Aâ€  
2. ğŸ§  **NLP Parsing** â†’ Extracts product + shelf  
3. ğŸš— **Navigation** â†’ Robot moves to shelf (distance-based + ultrasonic)  
4. ğŸ‘ï¸ **Vision** â†’ Detects ArUco marker, estimates 3D pose  
5. ğŸ¦¾ **IK + Arm Control** â†’ Computes servo angles, picks product  
6. ğŸ  **Return** â†’ Robot goes back to home position  

---

## ğŸ“Š Results  
- âœ… **Detection Accuracy:** 95%  
- âœ… **IK Success Rate:** 90%  
- âœ… **Pick-and-Place Success:** 85% (40 trials)  
- ğŸ’¡ Demonstrated **affordable, modular assistive robotics system**  

---

## ğŸ”® Future Improvements  
ğŸ”¹ SLAM-based autonomous navigation  
ğŸ”¹ AI-driven object detection (YOLO/MobileNet-SSD)  
ğŸ”¹ Adaptive soft gripper with force sensors  
ğŸ”¹ Multi-object retrieval task scheduling  
ğŸ”¹ Better voice interface with offline NLP  

---

## ğŸ“¸ Demo & Media  
ğŸ‘‰   ![two](https://github.com/user-attachments/assets/16dc69cf-2804-424c-8171-89c239281787)
![Bot_Movement_to_Shelf](https://github.com/user-attachments/assets/38791b60-33f4-4553-bc83-c2b7dcc886d1)
![Final_output](https://github.com/user-attachments/assets/5b762158-22e5-4829-9bfd-aab4445fed9c)


---

## ğŸ‘¨â€ğŸ’» Author  
**Sreerag S S**  
- ğŸ“ M.Tech Robotics & Automation, College of Engineering Trivandrum  
- ğŸŒ [LinkedIn](https://linkedin.com/in/sreerag-s-s-05483a140)  
- ğŸ’» [GitHub](https://github.com/sreeragss)  

---

â­ If you like this project, donâ€™t forget to **star the repo** and share feedback!  
